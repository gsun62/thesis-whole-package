{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from scipy.stats import spearmanr, kendalltau, pearsonr\n",
    "from mplsoccer import Pitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print out top players over the entire data (on an arbitrary level)\n",
    "def top_players(df, metric):\n",
    "    print(f'Top players by {metric}')\n",
    "    return df.sort_values(by=metric, ascending=False)\n",
    "\n",
    "# Function to show top players for each position\n",
    "def top_players_by_position(df, metric):\n",
    "    grouped = df.groupby('position_primary').apply(lambda x: x.sort_values(by=metric, ascending=False))\n",
    "    return grouped\n",
    "\n",
    "# Function to show top players by event type\n",
    "def top_players_by_event(df, metric):\n",
    "    grouped = df.groupby('type').apply(lambda x: x.sort_values(by=metric, ascending=False))\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_metric(game_df, metric, n_bootstrap):\n",
    "    bootstrap_results = {}\n",
    "    \n",
    "    # Group data by player-season first\n",
    "    player_season_groups = game_df.groupby(['season', 'player'])\n",
    "    for (season, player), group in player_season_groups:\n",
    "        key = (season, player)\n",
    "        bootstrap_results[key] = []\n",
    "        \n",
    "        # Get unique matches for this player-season\n",
    "        player_matches = group['match_id'].unique()\n",
    "        num_matches = len(player_matches)\n",
    "            \n",
    "        # Perform bootstrap iterations for this player-season\n",
    "        for i in range(n_bootstrap):\n",
    "            bootstrap_match_ids = np.random.choice(player_matches, size=num_matches, replace=True)\n",
    "            bootstrap_data = pd.concat([group[group['match_id'] == match_id] for match_id in bootstrap_match_ids])\n",
    "            \n",
    "            # Calculate the metric sum for this bootstrap sample\n",
    "            metric_sum = bootstrap_data[metric].sum()\n",
    "            bootstrap_results[key].append(metric_sum)\n",
    "    \n",
    "    # Calculate variance for each player-season\n",
    "    player_variances = {}\n",
    "    for key, values in bootstrap_results.items():\n",
    "        if len(values) > 1:  # Only calculate variance if we have multiple samples\n",
    "            player_variances[key] = np.var(values)\n",
    "    \n",
    "    return np.mean(list(player_variances.values()))\n",
    "\n",
    "# Compute and print out metric season-to-season stabiity\n",
    "def metric_stability(season_df, metric):\n",
    "    player_vars = season_df.groupby('player')[metric].var()\n",
    "    total_var = season_df[metric].var()\n",
    "    print(f'Season-to-season Stability: {1 - player_vars.mean() / total_var}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare 2 same length lists of rankings and output the spearman rank correlation and kendall tau distance\n",
    "def compare_rankings(rankings1, rankings2):\n",
    "    if len(rankings1) != len(rankings2):\n",
    "        raise ValueError(\"Both rankings must have the same length.\")\n",
    "\n",
    "    spearman_corr, _ = spearmanr(rankings1, rankings2)\n",
    "    kendall_tau, _ = kendalltau(rankings1, rankings2)\n",
    "\n",
    "    return {\n",
    "        \"Spearman\": spearman_corr,\n",
    "        \"Kendall Tau\": kendall_tau,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping together positions\n",
    "position_groups = {\n",
    "    'Forwards': [\n",
    "        'Center Forward',\n",
    "        'Left Center Forward', \n",
    "        'Right Center Forward',\n",
    "    ],\n",
    "    \n",
    "    'Attacking Midfielders': [\n",
    "        'Center Attacking Midfield',\n",
    "        'Left Attacking Midfield',\n",
    "        'Right Attacking Midfield',\n",
    "        'Left Wing',\n",
    "        'Right Wing'\n",
    "    ],\n",
    "    \n",
    "    'Central Midfielders': [\n",
    "        'Right Midfield',\n",
    "        'Right Center Midfield',\n",
    "        'Center Midfield',\n",
    "        'Left Center Midfield',\n",
    "        'Left Midfield'\n",
    "    ],\n",
    "    \n",
    "    'Defensive Midfielders': [\n",
    "        'Center Defensive Midfield',\n",
    "        'Left Defensive Midfield',\n",
    "        'Right Defensive Midfield',\n",
    "        'Left Wing Back',\n",
    "        'Right Wing Back'\n",
    "    ],\n",
    "    \n",
    "    'Backs': [\n",
    "        'Left Back',\n",
    "        'Right Back',\n",
    "        'Center Back',\n",
    "        'Left Center Back',\n",
    "        'Right Center Back',\n",
    "    ],\n",
    "    'Goalkeeper': ['Goalkeeper']\n",
    "}\n",
    "\n",
    "# Create a mapping from individual position to group\n",
    "position_to_group = {}\n",
    "for group, positions in position_groups.items():\n",
    "    for position in positions:\n",
    "        position_to_group[position] = group\n",
    "\n",
    "# Color scheme that follows field positioning logic\n",
    "group_colors_position = {\n",
    "    'Backs': '#0000FF',             # Blue\n",
    "    'Defensive Midfielders': '#4169E1',  # Royal Blue\n",
    "    'Central Midfielders': '#008000',    # Green\n",
    "    'Attacking Midfielders': '#32CD32',  # Lime Green\n",
    "    'Forwards': '#FF0000',           # Red\n",
    "    'Goalkeeper': '#FFA500'         # Orange\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping together various event types\n",
    "event_groups = {\n",
    "    'Attacking Actions': [\n",
    "        'Carry', \n",
    "        'Pass', \n",
    "        'Shot'\n",
    "    ],\n",
    "    \n",
    "    'Defensive Actions': [\n",
    "        'Pressure', \n",
    "        'Block', \n",
    "        'Interception', \n",
    "        'Clearance', \n",
    "        'Shield'\n",
    "    ],\n",
    "    \n",
    "    'Other Actions': [\n",
    "        'Goal Keeper',\n",
    "        '50/50'\n",
    "    ],\n",
    "    \n",
    "    'Fouls & Offenses': [\n",
    "        'Foul Committed',\n",
    "        'Yellow Card',\n",
    "        'Second Yellow',\n",
    "        'Red Card',\n",
    "        'Offside'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a mapping from individual event to group\n",
    "event_to_group = {}\n",
    "for group, events in event_groups.items():\n",
    "    for event in events:\n",
    "        event_to_group[event] = group\n",
    "\n",
    "# Color scheme\n",
    "group_colors_event = {\n",
    "    'Attacking Actions': '#FF0000',      # Red\n",
    "    'Defensive Actions': '#0000FF',      # Blue\n",
    "    'Other Actions': '#FFA500',     # Orange\n",
    "    'Fouls & Offenses': '#8B0000'      # Dark Red\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_distributions(df, metric, feature, use_groups=False, show_counts=False, plot_type='violinplot'):\n",
    "    \"\"\"\n",
    "    Creates boxplots or violin plots of metrics by feature with optional grouping.\n",
    "    Parameters:\n",
    "    - df: DataFrame with the data\n",
    "    - metric: Column name for the metric to plot\n",
    "    - feature: Column name for the feature (e.g., 'position', 'event_type')\n",
    "    - use_groups: Whether to use predefined groups for visualization\n",
    "    - show_counts: Whether to display observation counts (default: False)\n",
    "    - plot_type: Type of plot to use ('boxplot' or 'violinplot', default: 'boxplot')\n",
    "    \"\"\"\n",
    "    data = df.dropna(subset=[metric, feature])\n",
    "    means = df.groupby(feature)[metric].mean()\n",
    "    print(f'f={feature} Stability: {1 - np.var(means) / np.var(data[metric])}')\n",
    "    \n",
    "    if use_groups:\n",
    "        # Make a copy to avoid SettingWithCopyWarning\n",
    "        data = data.copy()\n",
    "        \n",
    "        # Select appropriate mapping and order based on group_type\n",
    "        if 'position' in feature.lower():\n",
    "            mapping = position_to_group\n",
    "            group_column = 'position_group'\n",
    "            group_order = ['Goalkeeper', 'Backs', 'Defensive Midfielders', \n",
    "                          'Central Midfielders', 'Attacking Midfielders', 'Forwards']\n",
    "            groups_dict = position_groups\n",
    "            colors_dict = group_colors_position\n",
    "        elif feature.lower() == 'type':\n",
    "            mapping = event_to_group\n",
    "            group_column = 'event_group'\n",
    "            group_order = ['Other Actions', 'Defensive Actions', \n",
    "                          'Attacking Actions', 'Fouls & Offenses']\n",
    "            groups_dict = event_groups\n",
    "            colors_dict = group_colors_event\n",
    "        else:\n",
    "            raise ValueError(\"group_type must be 'position' or 'event'\")\n",
    "            \n",
    "        # Set up groups\n",
    "        data[group_column] = data[feature].map(mapping)\n",
    "        group_order = [group for group in group_order if group in data[group_column].unique()]\n",
    "        items_in_groups = {}\n",
    "        colors_by_item = {}\n",
    "        \n",
    "        for group in group_order:\n",
    "            items = [item for item in groups_dict[group] \n",
    "                    if item in data[feature].unique()]\n",
    "            items_in_groups[group] = items\n",
    "            # Assign the group color to each item\n",
    "            for item in items:\n",
    "                colors_by_item[item] = colors_dict[group]\n",
    "        \n",
    "        # Create a sorted list of all items to display\n",
    "        all_items = []\n",
    "        for group in group_order:\n",
    "            all_items.extend(items_in_groups[group])\n",
    "        \n",
    "        # Create plot with ordered items\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        if plot_type.lower() == 'violinplot':\n",
    "            ax = sns.violinplot(x=feature, y=metric, data=data, \n",
    "                               order=all_items, palette=colors_by_item)\n",
    "        else:\n",
    "            ax = sns.boxplot(x=feature, y=metric, data=data, \n",
    "                            order=all_items, palette=colors_by_item)\n",
    "        \n",
    "        # Add observation count labels if show_counts is True\n",
    "        if show_counts:\n",
    "            y_max_global = data[metric].max()\n",
    "            for i, item in enumerate(all_items):\n",
    "                count = len(data[data[feature] == item])\n",
    "                formatted_count = f\"{count:,}\"\n",
    "                \n",
    "                # Set text position: use either group max or a fixed position above global max\n",
    "                y_max = data[data[feature] == item][metric].max()\n",
    "                text_y = max(y_max * 1.05, y_max_global * 1.02, ax.get_ylim()[1]*0.92)\n",
    "                ax.text(i, text_y, f\"n={formatted_count}\", \n",
    "                       ha='center', va='bottom', color='black', fontweight='bold', fontsize=9)\n",
    "        \n",
    "        # Add visual group separators\n",
    "        curr_pos = 0\n",
    "        for i, group in enumerate(group_order):\n",
    "            if i > 0: # No line before the first group\n",
    "                plt.axvline(x=curr_pos - 0.5, color='gray', linestyle='--', alpha=0.7)\n",
    "            curr_pos += len(items_in_groups[group])\n",
    "        # Add a legend for groups\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [Patch(facecolor=colors_dict[group], edgecolor='black', label=group) \n",
    "                          for group in group_order]\n",
    "        plt.legend(handles=legend_elements, loc='upper right')\n",
    "        \n",
    "    else: # No groups case\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        if plot_type.lower() == 'violinplot':\n",
    "            ax = sns.violinplot(x=feature, y=metric, data=data)\n",
    "        else:\n",
    "            ax = sns.boxplot(x=feature, y=metric, data=data)\n",
    "        \n",
    "        # Add observation count labels for non-grouped version if show_counts is True\n",
    "        if show_counts:\n",
    "            y_max_global = data[metric].max()\n",
    "            for i, item in enumerate(sorted(data[feature].unique())):\n",
    "                count = len(data[data[feature] == item])\n",
    "                formatted_count = f\"{count:,}\"\n",
    "                \n",
    "                y_max = data[data[feature] == item][metric].max()\n",
    "                text_y = max(y_max * 1.05, y_max_global * 1.02, ax.get_ylim()[1]*0.92)   \n",
    "                ax.text(i, text_y, f\"n={formatted_count}\", \n",
    "                       ha='center', va='bottom', color='black', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(f'{metric} by {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(metric)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "df = pd.read_csv(\"data/processed_events.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "keep_columns = ['season', 'match_id', 'id', 'ts_minute', 'minute', 'second', 'location', 'zone', 'type', 'possession', 'possession_team', 'possession_team_id', 'play_pattern', 'team', 'team_id', 'player', 'player_id', 'position', 'obv_for_net', 'obv_against_net', 'obv_total_net', 'duration', 'under_pressure', 'substitution_replacement', 'substitution_replacement_id', 'tactics', 'shot_outcome', 'shot_statsbomb_xg', 'pass_goal_assist']\n",
    "df = df[keep_columns] \n",
    "df['obv_for_net'] = df['obv_for_net'].astype(float)\n",
    "df['obv_against_net'] = df['obv_against_net'].astype(float)\n",
    "df['obv_total_net'] = df['obv_total_net'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in metrics\n",
    "train_metrics = pd.read_csv(\"data/train_metrics.csv\")\n",
    "actions = train_metrics\n",
    "\n",
    "# # Alternatively, read in train and test:\n",
    "# test_metrics = pd.read_csv(\"data/test_metrics.csv\") \n",
    "# actions = pd.concat([train_metrics, test_metrics]).reset_index(drop=True)\n",
    "\n",
    "# Filter metrics data\n",
    "cols_to_use = ['id', 'season', 'zone', 'shot_outcome', 'shot_statsbomb_xg', 'pass_goal_assist']\n",
    "actions = pd.merge(actions, df[cols_to_use], on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the metrics of interest\n",
    "metrics = ['VAEP', 'GPA', 'WPA', 'WPA2']\n",
    "\n",
    "# Compute stats for each unique (match, player)\n",
    "game_stats = actions.groupby(['season', 'match_id', 'player', 'team']).agg(\n",
    "    {**{metric: 'sum' for metric in metrics}, **{f'{metric}_norm': 'sum' for metric in metrics}}\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Identify entry times of starters and substitutes\n",
    "def parse_lineup(row, event_type):\n",
    "    if row['type'] == event_type:\n",
    "        tactics_data = ast.literal_eval(row['tactics'])\n",
    "        lineup = tactics_data.get('lineup', [])\n",
    "        parsed_data = [\n",
    "            {\n",
    "                'match_id': row['match_id'],\n",
    "                'player': player['player']['name'],\n",
    "                'player_id': player['player']['id'],\n",
    "                'position': player['position']['name'],\n",
    "                'team': row['team'],\n",
    "                'ts_minute': row['ts_minute']  # Starting players enter at the start of the match\n",
    "            }\n",
    "            for player in lineup\n",
    "        ]\n",
    "        return parsed_data\n",
    "    return []\n",
    "\n",
    "# Apply parsing to extract all starting lineups\n",
    "starting = df.apply(parse_lineup, args=(\"Starting XI\", ), axis=1).explode().dropna()\n",
    "starting_df = pd.DataFrame(starting.tolist()) \n",
    "starting_df = starting_df.rename(columns={'ts_minute': 'entry_time'})\n",
    "\n",
    "sub_in_df = df[df['type'] == 'Substitution']\n",
    "sub_in_df = sub_in_df.drop(columns=['player'])\n",
    "sub_in_df = sub_in_df.rename(columns={'substitution_replacement': 'player', 'ts_minute': 'entry_time'})\n",
    "entry_times = pd.concat([starting_df.reset_index(drop=True), sub_in_df.reset_index(drop=True)])[['player', 'match_id', 'entry_time']]\n",
    "\n",
    "# Identify exit times \n",
    "sub_out_df = df[df['type'] == 'Substitution']\n",
    "sub_out_df = sub_out_df.rename(columns={'ts_minute': 'exit_time'})\n",
    "match_end_df = df.groupby('match_id')['ts_minute'].max().reset_index()\n",
    "match_end_df = match_end_df.rename(columns={'ts_minute': 'exit_time'})\n",
    "# Assign match end times as the default exit time for all players\n",
    "default_exit_times = entry_times[['match_id', 'player']].merge(match_end_df, on='match_id', how='left')\n",
    "exit_times = pd.concat([sub_out_df, default_exit_times]).drop_duplicates(subset=['match_id', 'player'], keep='first')[['player', 'match_id', 'exit_time']]\n",
    "\n",
    "# Merge entry and exit times\n",
    "play_times = pd.merge(entry_times, exit_times, on=['match_id', 'player'], how='inner')\n",
    "# convert times to timestamps\n",
    "play_times['minutes_played'] = (play_times['exit_time'] - play_times['entry_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Find all tactical shifts and extract the players involved\n",
    "shifts = df.apply(parse_lineup, args=(\"Tactical Shift\", ), axis=1).explode().dropna()\n",
    "shifts_df = pd.DataFrame(shifts.tolist()) \n",
    "\n",
    "positions = pd.concat([shifts_df, df], axis=0).dropna(subset=['position'])\n",
    "positions = positions[positions['position'] != 'Substitute'] # accounting for extra data (bad behavior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Identify times of position changes\n",
    "positions = positions.sort_values(by=['match_id', 'player', 'ts_minute']).drop_duplicates(subset=['match_id', 'player', 'position'], keep='first').reset_index(drop=True)\n",
    "positions['next_ts_minute'] = positions.groupby(['match_id', 'player'])['ts_minute'].shift(-1)\n",
    "player_exit_times = play_times[['match_id', 'player', 'exit_time']].copy()\n",
    "positions = positions.merge( \n",
    "    player_exit_times[['match_id', 'player', 'exit_time']],\n",
    "    on=['match_id', 'player'], how='left'\n",
    ")\n",
    "\n",
    "# Calculate durations\n",
    "positions['duration'] = (positions['next_ts_minute']\n",
    "                  .fillna(positions['exit_time']) - positions['ts_minute'])\n",
    "\n",
    "# Aggregate unique positions and durations\n",
    "positions = positions.groupby(['match_id', 'player']).agg({\n",
    "    'position': lambda x: list(x),\n",
    "    'duration': lambda x: list(x) \n",
    "}).reset_index()\n",
    "# Rename columns for clarity\n",
    "positions = positions.rename(columns={'position': 'positions', 'duration': 'durations'})\n",
    "\n",
    "# Create column for the element in the positions column with the longest associated duration, also store that duration. Then make a column with the length of positions\n",
    "positions['duration_position_primary'] = positions.apply(lambda x: max(x['durations']), axis=1)\n",
    "positions['position_primary'] = positions.apply(lambda x: x['positions'][x['durations'].index(x['duration_position_primary'])], axis=1)\n",
    "positions['num_positions'] = positions['positions'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Get number of shots, number of goals, total XG for each (match_id, player) pair\n",
    "shots = actions[actions['type'] == 'Shot']\n",
    "goals = shots[shots['shot_outcome'] == 'Goal'].groupby(['match_id', 'player']).size().reset_index(name='goals')\n",
    "shots_count = shots.groupby(['match_id', 'player']).size().reset_index(name='shots')\n",
    "shots_count = pd.merge(shots_count, goals, on=['match_id', 'player'], how='left')\n",
    "shots_count['goals'] = shots_count['goals'].fillna(0).astype(int)\n",
    "# Sum up shot_statsbomb_xg for each (match_id, player)\n",
    "xg = shots.groupby(['match_id', 'player'])['shot_statsbomb_xg'].sum().reset_index(name='total_xg')\n",
    "shots_count = pd.merge(shots_count, xg, on=['match_id', 'player'], how='left')\n",
    "\n",
    "# Compute assist stats\n",
    "passes = actions[actions['type'] == 'Pass']\n",
    "assists = passes[passes['pass_goal_assist'] == True].groupby(['match_id', 'player']).size().reset_index(name='assists')\n",
    "shots_count = pd.merge(shots_count, assists, on=['match_id', 'player'], how='left')\n",
    "shots_count['assists'] = shots_count['assists'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge player minutes data onto original data\n",
    "game_stats = pd.merge(game_stats, play_times, on=['match_id', 'player'], how='left')\n",
    "game_stats = pd.merge(game_stats, positions, on=['match_id', 'player'], how='left')\n",
    "game_stats = pd.merge(game_stats, shots_count, on=['match_id', 'player'], how='left')\n",
    "game_stats['shots'] = game_stats['shots'].fillna(0)\n",
    "game_stats['goals'] = game_stats['goals'].fillna(0)\n",
    "game_stats['assists'] = game_stats['assists'].fillna(0)\n",
    "game_stats['total_xg'] = game_stats['total_xg'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the metric columns by minutes played\n",
    "for metric in metrics:\n",
    "    game_stats[f'{metric}_per_90'] = game_stats[metric] / game_stats['minutes_played'] * 90\n",
    "    game_stats[f'{metric}_norm_per_90'] = game_stats[f'{metric}_norm'] / game_stats['minutes_played'] * 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate season stats dynamically\n",
    "season_stats = game_stats.groupby(['season', 'player']).agg(\n",
    "    {**{metric: 'sum' for metric in metrics}, **{f'{metric}_norm': 'sum' for metric in metrics}, **{'minutes_played': 'sum', 'shots': 'sum', 'goals': 'sum', 'assists': 'sum', 'total_xg': 'sum'}}\n",
    ").reset_index()\n",
    "\n",
    "# Add a column for position_primary based on the highest total duration_position_primary\n",
    "position_time = game_stats.groupby(['season', 'player', 'position_primary'])['duration_position_primary'].sum().reset_index()\n",
    "primary_position_season = position_time.loc[\n",
    "    position_time.groupby(['season', 'player'])['duration_position_primary'].idxmax()\n",
    "]\n",
    "primary_position_season = primary_position_season.rename(columns={'duration_position_primary': 'minutes_position_primary'})\n",
    "season_stats = pd.merge(season_stats, primary_position_season, on=['season', 'player'], how='left')\n",
    "\n",
    "# Dynamically create per 90-minute statistics for all relevant metrics\n",
    "for metric in metrics:\n",
    "    season_stats[f'{metric}_per_90'] = season_stats[metric] / season_stats['minutes_played'] * 90\n",
    "    season_stats[f'{metric}_norm_per_90'] = season_stats[f'{metric}_norm'] / season_stats['minutes_played'] * 90\n",
    "\n",
    "    # Add metric contributions from each event type dynamically\n",
    "    for event_type in ['Shot', 'Pass', 'Dribble', 'Interception', 'Block']:\n",
    "        obv_by_event = actions[actions['type'] == event_type].groupby(['season', 'player']).agg({metric: 'sum'}).reset_index()\n",
    "        obv_by_event = obv_by_event.rename(columns={metric: f'{metric}_{event_type}'})\n",
    "        \n",
    "        season_stats = pd.merge(season_stats, obv_by_event, on=['season', 'player'], how='left')\n",
    "        season_stats[f'{metric}_{event_type}'] = season_stats[f'{metric}_{event_type}'].fillna(0)\n",
    "        season_stats[f'{metric}_{event_type}_per_90'] = season_stats[f'{metric}_{event_type}'] / season_stats['minutes_played'] * 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the game and season stats\n",
    "# game_stats.to_csv('data/train_game_stats.csv', index=False)\n",
    "# season_stats.to_csv('data/train_season_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top players\n",
    "game_threshold = 30\n",
    "season_threshold = 500\n",
    "game = game_stats[game_stats['minutes_played'] >= game_threshold]\n",
    "season = season_stats[season_stats['minutes_played'] >= season_threshold]\n",
    "metric_base = 'WPA'\n",
    "metric = f'{metric_base}_per_90'\n",
    "\n",
    "print(\"Top individual performances:\") # overall best performances\n",
    "display(top_players(game, metric)[['season', 'match_id', 'player', 'position_primary', metric]].head(10))\n",
    "print(\"Top season players:\")\n",
    "for s in season['season'].unique(): # statistical leaders for each season\n",
    "    print(f\"Season {s}\")\n",
    "    display(top_players(season[season['season'] == s], metric)[['player', 'position_primary', metric]].head(10))\n",
    "\n",
    "    print(f\"Compared to goals: {compare_rankings(season.loc[season['season'] == s, metric].rank(ascending=False), season.loc[season['season'] == s, 'goals'].rank(ascending=False))}\")\n",
    "    print(f\"Compared to goals + assists: {compare_rankings(season.loc[season['season'] == s, metric].rank(ascending=False), (season.loc[season['season'] == s, 'goals'] + season.loc[season['season'] == s, 'assists']).rank(ascending=False))}\")\n",
    "    print(f\"Compared to Total xG: {compare_rankings(season.loc[season['season'] == s, metric].rank(ascending=False), season.loc[season['season'] == s, 'total_xg'].rank(ascending=False))}\")\n",
    "\n",
    "# Compute metric stability and distributions\n",
    "metric_stability(game, season, metric)\n",
    "metric_distributions(actions, metric_base, 'position', use_groups=True)\n",
    "metric_distributions(actions, metric_base, 'type', use_groups=True, plot_type='violinplot')\n",
    "metric_distributions(actions, metric_base, 'goal_diff_start', show_counts=True, plot_type='violinplot')\n",
    "print(f\"Game-Level {metric} by Position\")\n",
    "metric_distributions(game, metric, 'position_primary', use_groups=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap of the metric by zone\n",
    "def create_zone_heatmap(df, metric_column):\n",
    "    # Pitch setup\n",
    "    field_length = 120 \n",
    "    field_width = 80 \n",
    "    horizontal_zones = 5\n",
    "    vertical_zones = 7\n",
    "    horizontal_lines = np.linspace(0, field_width, horizontal_zones + 1)\n",
    "    vertical_lines = np.linspace(0, field_length, vertical_zones + 1)\n",
    "    \n",
    "    # Aggregate the metric by zone\n",
    "    zone_metrics = df.groupby('zone')[metric_column].median().reset_index()\n",
    "    heatmap_data = np.zeros((horizontal_zones, vertical_zones))\n",
    "    for _, row in zone_metrics.iterrows():\n",
    "        zone = row['zone']\n",
    "        i, j = map(int, zone.replace('Zone ', '').split('-'))\n",
    "        # Convert to 0-based indexing\n",
    "        i -= 1\n",
    "        j -= 1\n",
    "        heatmap_data[i, j] = row[metric_column]\n",
    "    \n",
    "    # Create a pitch using mplsoccer\n",
    "    pitch = Pitch(pitch_type='custom', pitch_length=field_length, pitch_width=field_width, \n",
    "                  line_color='black', line_zorder=2)\n",
    "    fig, ax = pitch.draw(figsize=(12, 8))\n",
    "    X, Y = np.meshgrid(vertical_lines, horizontal_lines)\n",
    "    # Create a custom colormap (blue to red)\n",
    "    cmap = plt.cm.RdYlBu_r  # Red-Yellow-Blue colormap reversed (high=red, low=blue)\n",
    "    # Create the heatmap\n",
    "    mesh = ax.pcolormesh(X, Y, heatmap_data, cmap=cmap, alpha=0.5, zorder=1)\n",
    "    # Add a colorbar\n",
    "    cbar = plt.colorbar(mesh, ax=ax)\n",
    "    cbar.set_label(metric_column)\n",
    "    \n",
    "    # Add only the metric values in the cells\n",
    "    for i in range(horizontal_zones):\n",
    "        for j in range(vertical_zones):\n",
    "            # Calculate center of the zone\n",
    "            x_center = (vertical_lines[j] + vertical_lines[j + 1]) / 2\n",
    "            y_center = (horizontal_lines[i] + horizontal_lines[i + 1]) / 2\n",
    "            # Add text with the metric value\n",
    "            value = heatmap_data[i, j]\n",
    "            ax.text(x_center, y_center, f\"{value:.2f}\", ha='center', va='center', \n",
    "                   fontsize=9, color='black', fontweight='bold', zorder=3)\n",
    "    \n",
    "    # Add row labels (first number in zone) on the y-axis\n",
    "    for i in range(horizontal_zones):\n",
    "        # Calculate the middle of each row\n",
    "        y_pos = (horizontal_lines[i] + horizontal_lines[i + 1]) / 2\n",
    "        # Add text on the left side of the pitch\n",
    "        ax.text(-3, y_pos, f\"{i+1}\", ha='right', va='center', fontsize=10)\n",
    "    \n",
    "    # Add column labels (second number in zone) on the x-axis\n",
    "    for j in range(vertical_zones):\n",
    "        # Calculate the middle of each column\n",
    "        x_pos = (vertical_lines[j] + vertical_lines[j + 1]) / 2\n",
    "        # Add text below the pitch\n",
    "        ax.text(x_pos, field_width + 5, f\"{j+1}\", ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # Title and display\n",
    "    ax.set_title(f\"{metric_column} Heatmap by Zone\", fontsize=16)\n",
    "    plt.gca().invert_yaxis()  # Ensure (0,0) is at the top-left\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "# Create the heatmap\n",
    "fig, ax = create_zone_heatmap(actions, metric_base)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_metrics(df, metric1, metric2, data_type='season'):\n",
    "    # Compute Pearson correlation coefficient\n",
    "    corr_coef, _ = pearsonr(df[metric1], df[metric2])\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Choose scatter plot type based on data type\n",
    "    if data_type == 'season':\n",
    "        sns.scatterplot(data=df, x=metric1, y=metric2)\n",
    "    else:\n",
    "        # Bin scatter plot for game stats and actions\n",
    "        sns.regplot(data=df, x=metric1, y=metric2, \n",
    "                    scatter_kws={'alpha':0.5}, \n",
    "                    line_kws={'color': 'red'}, \n",
    "                    x_bins=10) \n",
    "\n",
    "    plt.text(\n",
    "        x=df[metric1].min(),\n",
    "        y=df[metric2].max(),\n",
    "        s=f\"Pearson r = {corr_coef:.2f}\",\n",
    "        fontsize=12,\n",
    "        color=\"red\"\n",
    "    )\n",
    "    # Add labels and grid\n",
    "    plt.title(f\"{metric2} vs. {metric1}\")\n",
    "    plt.xlabel(metric1)\n",
    "    plt.ylabel(metric2)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "compare_metrics(game_stats, 'GPA', 'WPA', data_type='season') # player-match level\n",
    "compare_metrics(actions, 'GPA', 'WPA', data_type='game') # action level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Examine specific cases: looking at extreme values\n",
    "\n",
    "# Condense displayed information\n",
    "detail_cols = ['ts_minute', 'ts_end', 'team', 'possession', 'season', 'player', 'obv_total_net','GPA', 'WPA', 'GPA_WPA_diff', 'position', 'type', 'team_score', 'opponent_score', 'goal_contribution', 'outcome']\n",
    "\n",
    "# Helper function for showing extreme action sequences\n",
    "def display_extreme_metrics(metric, actions=actions, condensed=False):\n",
    "    extreme = actions[detail_cols].sort_values(by=metric, ascending=False)\n",
    "    if condensed:\n",
    "        extreme = extreme[[metric, 'type', 'position', 'ts_minute', 'team_score', 'opponent_score', 'outcome']]\n",
    "    print('Top')\n",
    "    display(extreme.head(10))\n",
    "    print('Bottom')\n",
    "    display(extreme.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up two filters of the actions to avoid letting unreasonable outliers impact analysis\n",
    "\n",
    "# Helper functions\n",
    "def winsorize_actions(actions, metrics, lower, upper):\n",
    "    new_actions = actions.copy()\n",
    "    for metric in metrics:\n",
    "        lower_limit = actions[metric].quantile(lower)\n",
    "        upper_limit = actions[metric].quantile(upper)\n",
    "        new_actions[metric] = actions[metric].clip(lower=lower_limit, upper=upper_limit)\n",
    "    return new_actions\n",
    "def compute_diff(actions):\n",
    "    actions['GPA_WPA_diff'] = actions['GPA'] - actions['WPA']\n",
    "    return actions\n",
    "\n",
    "# Filter for actions starting on a new possession\n",
    "filtered_actions = compute_diff(actions[actions[['match_id', 'possession']].duplicated(keep='first')].reset_index(drop=True))\n",
    "# Winsorized actions, shaving off 2.5 percent of top and bottom extreme values\n",
    "new_actions = compute_diff(winsorize_actions(actions=filtered_actions, metrics=['GPA', 'WPA'], lower=0.025, upper=0.975))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the extreme values\n",
    "display_extreme_metrics('GPA', actions=filtered_actions, condensed=True)\n",
    "display_extreme_metrics('WPA', actions=filtered_actions, condensed=True)\n",
    "display_extreme_metrics('GPA_WPA_diff', actions=new_actions, condensed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for plotting a specific sequence of actions\n",
    "def plot_soccer_actions(actions_df, metric_column, title):\n",
    "    \"\"\"\n",
    "    Plot soccer actions on a pitch with team-colored arrows indicating movement and metric values.\n",
    "    Rotates coordinates to ensure consistent representation.\n",
    "    \"\"\"\n",
    "    # Pitch setup\n",
    "    PITCH_LENGTH = 120\n",
    "    PITCH_WIDTH = 80\n",
    "    pitch = Pitch(pitch_type='statsbomb')\n",
    "    fig, ax = pitch.draw(figsize=(16, 11))\n",
    "    ax.set_title(title, fontsize=20, color='black', fontweight='bold')\n",
    "\n",
    "    teams = actions_df['team'].unique()\n",
    "    # Default color palette (mplsoccer's standard colors)\n",
    "    default_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', \n",
    "                      '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "    team_colors = {team: default_colors[i % len(default_colors)] \n",
    "                   for i, team in enumerate(teams)}\n",
    "    \n",
    "    # Track existing label positions to avoid overlap\n",
    "    existing_labels = []\n",
    "    \n",
    "    def rotate_coordinates(x, y, team):\n",
    "        \"\"\"\n",
    "        Rotate coordinates so that all teams attack from left to right\n",
    "        \"\"\"\n",
    "        # If the team's goal is on the right side, rotate 180 degrees\n",
    "        if len(teams) > 1 and team == teams[1]:  # Assumes second team attacks right\n",
    "            # Rotate around pitch midpoint\n",
    "            rotated_x = PITCH_LENGTH - x\n",
    "            rotated_y = PITCH_WIDTH - y\n",
    "            return rotated_x, rotated_y\n",
    "        return x, y\n",
    "    \n",
    "    def is_overlapping(x, y, existing_labels, min_distance=2):\n",
    "        \"\"\"Check if a new label position overlaps with existing labels\"\"\"\n",
    "        for ex, ey in existing_labels:\n",
    "            if ((x - ex)**2 + (y - ey)**2)**0.5 < min_distance:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    # Plot each action\n",
    "    for i, action in enumerate(actions_df.iterrows(), 1):\n",
    "        action = action[1]\n",
    "        # Determine coordinate transformation based on team\n",
    "        team = action['team']\n",
    "        start_x = action['location_x']\n",
    "        start_y = action['location_y']\n",
    "        end_x = action['end_location_x']\n",
    "        end_y = action['end_location_y']  \n",
    "        # Rotate coordinates\n",
    "        start_x, start_y = rotate_coordinates(start_x, start_y, team)\n",
    "        end_x, end_y = rotate_coordinates(end_x, end_y, team)\n",
    "        \n",
    "        # Plot the metric values in the right colors\n",
    "        metric_value = action[metric_column]\n",
    "        line_color = team_colors[team]\n",
    "        pitch.arrows(start_x, start_y, end_x, end_y, \n",
    "                     width=2, headwidth=10, headlength=10, \n",
    "                     color=line_color, alpha=0.7, ax=ax)\n",
    "        # Add sequence numbers\n",
    "        ax.text(start_x, start_y, str(i), \n",
    "                color='white', \n",
    "                fontweight='bold', \n",
    "                fontsize=8,\n",
    "                bbox=dict(facecolor='black', alpha=0.7, edgecolor='none'),\n",
    "                ha='center', va='center')\n",
    "        \n",
    "        # Try to avoid overlapping text\n",
    "        mid_x = (start_x + end_x) / 2\n",
    "        mid_y = (start_y + end_y) / 2\n",
    "        # Different offset directions to avoid overlap\n",
    "        offsets = [\n",
    "            (2, 0),   # right\n",
    "            (-2, 0),  # left\n",
    "            (0, 2),   # up\n",
    "            (0, -2)   # down\n",
    "        ]\n",
    "        label_placed = False\n",
    "        for dx, dy in offsets:\n",
    "            test_x = mid_x + dx\n",
    "            test_y = mid_y + dy\n",
    "            if not is_overlapping(test_x, test_y, existing_labels):\n",
    "                # Place label and add to existing labels\n",
    "                ax.text(test_x, test_y, \n",
    "                        f'{metric_value:.2f}', \n",
    "                        color='white', \n",
    "                        fontweight='bold', \n",
    "                        fontsize=8,\n",
    "                        bbox=dict(facecolor=line_color, alpha=0.7, edgecolor='none'),\n",
    "                        ha='center', va='center')\n",
    "                existing_labels.append((test_x, test_y))\n",
    "                label_placed = True\n",
    "                break\n",
    "        # If all positions are taken, skip this label or use a fallback\n",
    "        if not label_placed:\n",
    "            print(f\"Warning: Could not place label for action {i}\")\n",
    "    \n",
    "    # Add a legend for teams\n",
    "    legend_elements = [plt.Line2D([0], [0], color=color, lw=4, label=team)\n",
    "                       for team, color in team_colors.items()]\n",
    "    fig.legend(handles=legend_elements, loc='lower center', \n",
    "               bbox_to_anchor=(0.5, 0),  # Position below the plot\n",
    "               ncol=len(teams),\n",
    "               facecolor='white', edgecolor='black', \n",
    "               title='Teams')\n",
    "    # Adjust layout to make room for the legend\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the indices of action sequence of interest\n",
    "start_action = 0 \n",
    "end_action = 1\n",
    "\n",
    "# Plot the actions\n",
    "fig, ax = plot_soccer_actions(filtered_actions.iloc[start_action:end_action], metric_column='GPA', title='Case Study')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
